# åŒ»è¯å¸‚åœºæ™ºèƒ½åˆ†æç³»ç»Ÿ - èšç±»åˆ†ææ¨¡å—å®Œæ•´å¼€å‘æ–‡æ¡£

> **æ¨¡å—**: æ ¸å¿ƒåˆ†æå¼•æ“ - K-Meansèšç±» + AIç­–ç•¥ç”Ÿæˆ
> **å½“å‰çŠ¶æ€**: å‰ç«¯UIæ¡†æ¶å®Œæˆï¼Œåç«¯APIå¾…å¼€å‘
> **å¼€å‘ä¼˜å…ˆçº§**: â­â­â­â­â­ (æœ€é«˜ä¼˜å…ˆçº§)

---

## ğŸ“‹ ç›®å½•

1. [ç³»ç»Ÿæ¶æ„å›é¡¾](#1-ç³»ç»Ÿæ¶æ„å›é¡¾)
2. [æ¨¡å—åŠŸèƒ½è®¾è®¡](#2-æ¨¡å—åŠŸèƒ½è®¾è®¡)
3. [æ•°æ®åº“è®¾è®¡](#3-æ•°æ®åº“è®¾è®¡)
4. [åç«¯å¼€å‘è¯¦è§£](#4-åç«¯å¼€å‘è¯¦è§£)
5. [å‰ç«¯å¼€å‘è¯¦è§£](#5-å‰ç«¯å¼€å‘è¯¦è§£)
6. [Difyé›†æˆæ–¹æ¡ˆ](#6-difyé›†æˆæ–¹æ¡ˆ)
7. [æµ‹è¯•æ–¹æ¡ˆ](#7-æµ‹è¯•æ–¹æ¡ˆ)
8. [éƒ¨ç½²æ¸…å•](#8-éƒ¨ç½²æ¸…å•)

---

## 1. ç³»ç»Ÿæ¶æ„å›é¡¾

### 1.1 æ ¸å¿ƒä¸‰å±‚æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          å‰ç«¯ Vue3 (å·²å®ŒæˆUIæ¡†æ¶)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ é…ç½®é¢æ¿   â”‚ ç»“æœå±•ç¤ºåŒº â”‚ AIæŠ¥å‘Šç”Ÿæˆ        â”‚  â”‚
â”‚  â”‚ - Kå€¼æ»‘å—  â”‚ - 3Dæ•£ç‚¹å›¾ â”‚ - å¯¹è¯å¼ç•Œé¢      â”‚  â”‚
â”‚  â”‚ - ç‰¹å¾é€‰æ‹© â”‚ - é›·è¾¾å›¾   â”‚ - Markdownæ¸²æŸ“    â”‚  â”‚
â”‚  â”‚ - å¼€å§‹åˆ†æ â”‚ - ç»Ÿè®¡è¡¨   â”‚ - æµå¼è¾“å‡º        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†• HTTP REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          åç«¯ FastAPI (æœ¬æ¬¡å¼€å‘é‡ç‚¹)                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ åˆ†ææœåŠ¡   â”‚ æ•°æ®å¤„ç†   â”‚ AIé›†æˆæœåŠ¡        â”‚  â”‚
â”‚  â”‚ analysis_  â”‚ data_      â”‚ dify_             â”‚  â”‚
â”‚  â”‚ service.py â”‚ processor  â”‚ service.py        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    æ•°æ®å±‚ & AIå±‚ (SQLite + Scikit-Learn + Dify)     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ doctors  â”‚ cluster_ â”‚ analysis_â”‚ ai_reports  â”‚  â”‚
â”‚  â”‚ (738K)   â”‚ results  â”‚ tasks    â”‚             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                     â”‚
â”‚  K-Meansç®—æ³• â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€ Difyæ™ºèƒ½ä½“         â”‚
â”‚  (Scikit-Learn)      â””â”€â”€â”˜     (LLMç­–ç•¥ç”Ÿæˆ)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 æ ¸å¿ƒä¸šåŠ¡æµç¨‹

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·
    participant F as å‰ç«¯
    participant B as åç«¯API
    participant K as K-MeansæœåŠ¡
    participant D as æ•°æ®åº“
    participant AI as Dify

    Note over U,AI: é˜¶æ®µä¸€ï¼šæ‰§è¡Œèšç±»åˆ†æ
    U->>F: 1. è®¾ç½®K=3ï¼Œé€‰æ‹©ç‰¹å¾
    F->>B: 2. POST /api/analysis/perform
    B->>D: 3. æŸ¥è¯¢doctorsè¡¨ï¼ˆ738KåŒ»ç”Ÿï¼‰
    D-->>B: è¿”å›RFMæ•°æ®
    B->>K: 4. æ‰§è¡ŒK-Meansèšç±»
    K-->>B: 5. è¿”å›èšç±»ç»“æœ
    B->>D: 6. æ›´æ–°doctors.cluster_id
    B->>D: 7. ä¿å­˜cluster_results
    B-->>F: 8. è¿”å›ä»»åŠ¡å®Œæˆ
    F->>F: 9. æ¸²æŸ“å¯è§†åŒ–å›¾è¡¨
  
    Note over U,AI: é˜¶æ®µäºŒï¼šAIç­–ç•¥ç”Ÿæˆ
    U->>F: 10. ç‚¹å‡»"ç”ŸæˆAIç­–ç•¥"
    F->>B: 11. POST /api/reports/generate
    B->>D: 12. æŸ¥è¯¢cluster_results
    D-->>B: è¿”å›èšç±»ç»Ÿè®¡æ•°æ®
    B->>AI: 13. è°ƒç”¨Difyå·¥ä½œæµ
    AI-->>B: 14. æµå¼è¿”å›ç­–ç•¥æŠ¥å‘Š
    B-->>F: 15. SSEæµå¼ä¼ è¾“
    F->>F: 16. å®æ—¶æ¸²æŸ“Markdown
```

### 1.3 å…³é”®æ•°æ®æµ

```
åŸå§‹æ•°æ®ï¼ˆdoctorsè¡¨ï¼‰
  738,772ååŒ»ç”Ÿ
  â†“ [æŸ¥è¯¢]
RFMç‰¹å¾çŸ©é˜µ
  (738772 Ã— 2) â†’ [Frequency, Monetary]
  â†“ [æ ‡å‡†åŒ–]
æ ‡å‡†åŒ–æ•°æ®
  StandardScaler: mean=0, std=1
  â†“ [K-Meansèšç±»]
èšç±»æ ‡ç­¾
  æ¯ä¸ªåŒ»ç”Ÿ â†’ cluster_id (0, 1, 2)
  â†“ [ç»Ÿè®¡è®¡ç®—]
èšç±»ä¸­å¿ƒç‰¹å¾
  {
    "cluster_0": {avg_F: 50, avg_M: 10000},
    "cluster_1": {avg_F: 15, avg_M: 3000},
    "cluster_2": {avg_F: 3, avg_M: 200}
  }
  â†“ [ä¼ é€’ç»™Dify]
AIç­–ç•¥æŠ¥å‘Š
  "é’ˆå¯¹cluster_0é«˜ä»·å€¼å®¢æˆ·ï¼Œå»ºè®®..."
```

---

## 2. æ¨¡å—åŠŸèƒ½è®¾è®¡

### 2.1 æ ¸å¿ƒåŠŸèƒ½æ¸…å•

```
èšç±»åˆ†ææ¨¡å—
â”œâ”€â”€ 2.1 é…ç½®ä¸æ‰§è¡Œ
â”‚   â”œâ”€â”€ Kå€¼é€‰æ‹©ï¼ˆ2-10ï¼‰
â”‚   â”œâ”€â”€ ç‰¹å¾é€‰æ‹©ï¼ˆR/F/Mï¼‰
â”‚   â”œâ”€â”€ ç®—æ³•é€‰æ‹©ï¼ˆå½“å‰ä»…K-Meansï¼Œæœªæ¥æ‰©å±•ï¼‰
â”‚   â”œâ”€â”€ ä»»åŠ¡å‘½å
â”‚   â””â”€â”€ å¼€å§‹åˆ†ææŒ‰é’®
â”‚
â”œâ”€â”€ 2.2 åˆ†æè¿‡ç¨‹
â”‚   â”œâ”€â”€ æ•°æ®åŠ è½½ï¼ˆ738KåŒ»ç”Ÿï¼‰
â”‚   â”œâ”€â”€ æ•°æ®é¢„å¤„ç†ï¼ˆç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼ï¼‰
â”‚   â”œâ”€â”€ ç‰¹å¾å·¥ç¨‹ï¼ˆæ ‡å‡†åŒ–ï¼‰
â”‚   â”œâ”€â”€ K-Meansè®­ç»ƒ
â”‚   â”œâ”€â”€ è¯„ä¼°æŒ‡æ ‡è®¡ç®—ï¼ˆè½®å»“ç³»æ•°ã€æƒ¯æ€§ï¼‰
â”‚   â””â”€â”€ ç»“æœæŒä¹…åŒ–
â”‚
â”œâ”€â”€ 2.3 ç»“æœå±•ç¤º
â”‚   â”œâ”€â”€ èšç±»è¯„ä¼°æŒ‡æ ‡å¡ç‰‡
â”‚   â”‚   â”œâ”€â”€ è½®å»“ç³»æ•° (Silhouette Score)
â”‚   â”‚   â””â”€â”€ æƒ¯æ€§ (Inertia)
â”‚   â”œâ”€â”€ å¯è§†åŒ–å›¾è¡¨
â”‚   â”‚   â”œâ”€â”€ 3Dæ•£ç‚¹å›¾ï¼ˆäº¤äº’å¼æ—‹è½¬ï¼‰
â”‚   â”‚   â”œâ”€â”€ é›·è¾¾å›¾ï¼ˆç‰¹å¾å¯¹æ¯”ï¼‰
â”‚   â”‚   â””â”€â”€ ç®±çº¿å›¾ï¼ˆé‡‘é¢åˆ†å¸ƒï¼‰
â”‚   â””â”€â”€ ç»Ÿè®¡è¡¨æ ¼
â”‚       â”œâ”€â”€ å„èšç±»è§„æ¨¡
â”‚       â”œâ”€â”€ å¹³å‡RFMå€¼
â”‚       â””â”€â”€ ä¸šåŠ¡æ ‡ç­¾
â”‚
â”œâ”€â”€ 2.4 AIç­–ç•¥ç”Ÿæˆ
â”‚   â”œâ”€â”€ é€‰æ‹©ç›®æ ‡èšç±»
â”‚   â”œâ”€â”€ è‡ªå®šä¹‰Prompt
â”‚   â”œâ”€â”€ è°ƒç”¨Difyå·¥ä½œæµ
â”‚   â”œâ”€â”€ æµå¼æ¥æ”¶æŠ¥å‘Š
â”‚   â””â”€â”€ Markdownæ¸²æŸ“
â”‚
â””â”€â”€ 2.5 å†å²ç®¡ç†
    â”œâ”€â”€ æŸ¥çœ‹å†å²åˆ†æ
    â”œâ”€â”€ å¯¹æ¯”ä¸åŒKå€¼ç»“æœ
    â”œâ”€â”€ å¯¼å‡ºåˆ†ææŠ¥å‘Š
    â””â”€â”€ åˆ é™¤å†å²è®°å½•
```

### 2.2 ç”¨æˆ·äº¤äº’æµç¨‹

**åœºæ™¯1ï¼šé¦–æ¬¡ä½¿ç”¨**

```
1. ç”¨æˆ·è¿›å…¥"èšç±»åˆ†æ"é¡µé¢
2. çœ‹åˆ°ç©ºçŠ¶æ€ï¼š"è¯·é…ç½®å‚æ•°å¹¶å¼€å§‹åˆ†æ"
3. å·¦ä¾§é…ç½®é¢æ¿ï¼š
   - Kå€¼æ»‘å—é»˜è®¤ä¸º3
   - ç‰¹å¾é»˜è®¤é€‰ä¸­ F + M
4. ç‚¹å‡»"å¼€å§‹åˆ†æ"æŒ‰é’®
5. æ˜¾ç¤ºè¿›åº¦æ¡ï¼ˆæ¨¡æ‹Ÿè¿›åº¦0â†’100%ï¼‰
6. 15ç§’åå®Œæˆï¼ˆå®é™…è®¡ç®—çº¦10ç§’ï¼‰
7. å³ä¾§å±•ç¤ºç»“æœï¼š
   - é¡¶éƒ¨ï¼šè¯„ä¼°æŒ‡æ ‡å¡ç‰‡
   - Tabsåˆ‡æ¢ï¼šæ•£ç‚¹å›¾/é›·è¾¾å›¾/ç»Ÿè®¡è¡¨
8. åº•éƒ¨ï¼š[ç”ŸæˆAIç­–ç•¥] [å¯¼å‡ºæŠ¥å‘Š] æŒ‰é’®
```

**åœºæ™¯2ï¼šè°ƒæ•´å‚æ•°é‡æ–°åˆ†æ**

```
1. ç”¨æˆ·ä¿®æ”¹K=4
2. ç‚¹å‡»"å¼€å§‹åˆ†æ"
3. å¼¹å‡ºç¡®è®¤ï¼š"æ˜¯å¦è¦†ç›–å½“å‰ç»“æœï¼Ÿ"
4. ç¡®è®¤åé‡æ–°åˆ†æ
5. æ›´æ–°æ‰€æœ‰å›¾è¡¨
6. æç¤ºï¼š"åˆ†æå®Œæˆï¼Œå…±å‘ç°4ä¸ªå®¢æˆ·ç¾¤"
```

**åœºæ™¯3ï¼šç”ŸæˆAIç­–ç•¥**

```
1. ç”¨æˆ·ç‚¹å‡»"ç”ŸæˆAIç­–ç•¥"
2. æ‰“å¼€å¯¹è¯æ¡†ï¼š
   - é€‰æ‹©ç›®æ ‡èšç±»ï¼ˆä¸‹æ‹‰æ¡†ï¼‰
   - è¾“å…¥è‡ªå®šä¹‰éœ€æ±‚ï¼ˆå¯é€‰ï¼‰
3. ç‚¹å‡»"å¼€å§‹ç”Ÿæˆ"
4. æ˜¾ç¤ºæ‰“å­—æœºæ•ˆæœçš„æµå¼è¾“å‡º
5. å®Œæˆåæ˜¾ç¤º[ä¿å­˜] [å¯¼å‡ºPDF] æŒ‰é’®
```

### 2.3 é”™è¯¯å¤„ç†

```
å¯èƒ½çš„é”™è¯¯æƒ…å†µï¼š

1. æ•°æ®ä¸è¶³
   - æ£€æŸ¥ï¼šdoctorsè¡¨è‡³å°‘100æ¡è®°å½•
   - æç¤ºï¼š"åŒ»ç”Ÿæ•°æ®ä¸è¶³ï¼Œè¯·å…ˆå¯¼å…¥æ•°æ®"

2. Kå€¼ä¸åˆç†
   - æ£€æŸ¥ï¼šKå¿…é¡» < doctorsæ•°é‡
   - æç¤ºï¼š"Kå€¼è¿‡å¤§ï¼Œå½“å‰æ•°æ®ä»…æ”¯æŒKâ‰¤10"

3. ç‰¹å¾ç¼ºå¤±
   - æ£€æŸ¥ï¼šè‡³å°‘é€‰æ‹©ä¸€ä¸ªç‰¹å¾
   - æç¤ºï¼š"è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªåˆ†æç‰¹å¾"

4. ç®—æ³•è¶…æ—¶
   - è®¾ç½®ï¼šæœ€å¤§æ‰§è¡Œæ—¶é—´120ç§’
   - æç¤ºï¼š"åˆ†æè¶…æ—¶ï¼Œè¯·å‡å°‘Kå€¼æˆ–æ•°æ®é‡"

5. Difyè°ƒç”¨å¤±è´¥
   - æ£€æŸ¥ï¼šAPI Keyæœ‰æ•ˆæ€§
   - æç¤ºï¼š"AIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•"
```

---

## 3. æ•°æ®åº“è®¾è®¡

### 3.1 æ ¸å¿ƒè¡¨ç»“æ„

#### è¡¨1: doctors (å·²å­˜åœ¨ï¼Œéœ€æ‰©å±•)

```sql
-- æ‰©å±•å­—æ®µ
ALTER TABLE doctors ADD COLUMN cluster_id INTEGER;
ALTER TABLE doctors ADD COLUMN cluster_label VARCHAR(50);
ALTER TABLE doctors ADD COLUMN updated_at DATETIME DEFAULT CURRENT_TIMESTAMP;

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_doctors_cluster ON doctors(cluster_id);
CREATE INDEX idx_doctors_updated ON doctors(updated_at);

-- ç¤ºä¾‹æ•°æ®
/*
npi           | cluster_id | cluster_label | rfm_frequency | rfm_monetary
1821157041    | 0          | é¡¶çº§å®¢æˆ·      | 493           | 91082706.03
1366487498    | 0          | é¡¶çº§å®¢æˆ·      | 3             | 26746052.32
1336242116    | 1          | æ½œåŠ›å®¢æˆ·      | 7             | 25000341.97
...
*/
```

#### è¡¨2: analysis_tasks (åˆ†æä»»åŠ¡è®°å½•)

```sql
CREATE TABLE analysis_tasks (
    task_id INTEGER PRIMARY KEY AUTOINCREMENT,
    task_name VARCHAR(200) NOT NULL,
    task_type VARCHAR(50) DEFAULT 'clustering',  -- 'clustering', 'rfm_analysis'
  
    -- ä»»åŠ¡å‚æ•°ï¼ˆJSONï¼‰
    parameters TEXT,  -- {"k": 3, "features": ["rfm_frequency", "rfm_monetary"]}
  
    -- ä»»åŠ¡çŠ¶æ€
    status VARCHAR(20) DEFAULT 'pending',  -- pending/running/completed/failed
    progress INTEGER DEFAULT 0,  -- 0-100
  
    -- æ‰§è¡Œä¿¡æ¯
    created_by INTEGER,  -- ç”¨æˆ·ID
    started_at DATETIME,
    completed_at DATETIME,
    execution_time REAL,  -- ç§’
    error_message TEXT,
  
    -- ç»“æœå…³è”
    result_id INTEGER,
  
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  
    FOREIGN KEY (created_by) REFERENCES users(id),
    FOREIGN KEY (result_id) REFERENCES cluster_results(cluster_id)
);

-- ç´¢å¼•
CREATE INDEX idx_tasks_status ON analysis_tasks(status);
CREATE INDEX idx_tasks_created_by ON analysis_tasks(created_by);
CREATE INDEX idx_tasks_created_at ON analysis_tasks(created_at DESC);

-- ç¤ºä¾‹æ•°æ®
/*
task_id | task_name           | status    | progress | result_id
1       | 2024Q4åŒ»ç”Ÿåˆ†ç¾¤     | completed | 100      | 1
2       | é«˜ä»·å€¼å®¢æˆ·ç­›é€‰     | completed | 100      | 2
3       | Kå€¼å¯¹æ¯”åˆ†æ        | running   | 45       | NULL
*/
```

#### è¡¨3: cluster_results (èšç±»ç»“æœ)

```sql
CREATE TABLE cluster_results (
    cluster_id INTEGER PRIMARY KEY AUTOINCREMENT,
    task_id INTEGER,
  
    -- èšç±»é…ç½®
    k_value INTEGER NOT NULL,
    algorithm VARCHAR(50) DEFAULT 'k-means',
    features_used TEXT,  -- JSON: ["rfm_frequency", "rfm_monetary"]
  
    -- èšç±»ç»Ÿè®¡ï¼ˆJSONï¼‰
    cluster_stats TEXT,
    /* æ ¼å¼ç¤ºä¾‹ï¼š
    {
      "0": {
        "size": 200000,
        "size_percentage": 27.1,
        "avg_frequency": 50.2,
        "avg_monetary": 12000.5,
        "median_frequency": 30,
        "median_monetary": 5000,
        "std_monetary": 8000,
        "label": "é¡¶çº§å®¢æˆ·",
        "characteristics": ["é«˜ä»·å€¼", "é«˜æ´»è·ƒ"]
      },
      "1": {...},
      "2": {...}
    }
    */
  
    -- ä¸šåŠ¡æ ‡ç­¾ï¼ˆJSONï¼‰
    cluster_labels TEXT,  -- {"0": "é¡¶çº§å®¢æˆ·", "1": "æ½œåŠ›å®¢æˆ·", "2": "å¤§ä¼—å®¢æˆ·"}
  
    -- æ¨¡å‹è¯„ä¼°
    silhouette_score REAL,  -- è½®å»“ç³»æ•° [-1, 1]ï¼Œè¶Šæ¥è¿‘1è¶Šå¥½
    inertia REAL,           -- æƒ¯æ€§ï¼ˆç°‡å†…å¹³æ–¹å’Œï¼‰
    davies_bouldin_score REAL,  -- DBæŒ‡æ•°ï¼Œè¶Šå°è¶Šå¥½ï¼ˆå¯é€‰ï¼‰
  
    -- å¯è§†åŒ–æ•°æ®ï¼ˆJSONï¼Œé‡‡æ ·åçš„æ•°æ®ï¼‰
    visualization_data TEXT,
    /* æ ¼å¼ç¤ºä¾‹ï¼š
    {
      "scatter_data": [
        {"frequency": 50, "monetary": 12000, "cluster": 0, "npi": "1234567890"},
        ...é‡‡æ ·1000ä¸ªç‚¹
      ],
      "cluster_centers": [[50.2, 12000.5], [15.3, 3000.1], [3.2, 200.8]],
      "radar_data": [
        {
          "cluster": "0",
          "label": "é¡¶çº§å®¢æˆ·",
          "normalized_frequency": 0.95,
          "normalized_monetary": 0.98
        },
        ...
      ]
    }
    */
  
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    is_active BOOLEAN DEFAULT 1,
  
    FOREIGN KEY (task_id) REFERENCES analysis_tasks(task_id)
);

-- ç´¢å¼•
CREATE INDEX idx_clusters_task ON cluster_results(task_id);
CREATE INDEX idx_clusters_active ON cluster_results(is_active);
CREATE INDEX idx_clusters_created ON cluster_results(created_at DESC);
```

#### è¡¨4: ai_reports (AIç­–ç•¥æŠ¥å‘Š)

```sql
CREATE TABLE ai_reports (
    report_id INTEGER PRIMARY KEY AUTOINCREMENT,
    report_title VARCHAR(300) NOT NULL,
    report_type VARCHAR(50) DEFAULT 'cluster_strategy',
  
    -- å…³è”æ•°æ®
    related_cluster_id INTEGER,
    related_cluster_label VARCHAR(50),
  
    -- æŠ¥å‘Šå†…å®¹
    report_content TEXT NOT NULL,  -- Markdownæ ¼å¼
    report_summary TEXT,  -- æ‘˜è¦ï¼ˆå‰300å­—ï¼‰
  
    -- ç”Ÿæˆä¿¡æ¯
    generated_by INTEGER,
    user_prompt TEXT,  -- ç”¨æˆ·è‡ªå®šä¹‰çš„Prompt
    dify_conversation_id VARCHAR(100),
    generation_time REAL,  -- ç”Ÿæˆè€—æ—¶ï¼ˆç§’ï¼‰
  
    -- ç»Ÿè®¡
    status VARCHAR(20) DEFAULT 'published',  -- draft/published/archived
    view_count INTEGER DEFAULT 0,
  
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  
    FOREIGN KEY (generated_by) REFERENCES users(id),
    FOREIGN KEY (related_cluster_id) REFERENCES cluster_results(cluster_id)
);

-- ç´¢å¼•
CREATE INDEX idx_reports_cluster ON ai_reports(related_cluster_id);
CREATE INDEX idx_reports_user ON ai_reports(generated_by);
CREATE INDEX idx_reports_created ON ai_reports(created_at DESC);
```

### 3.2 æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬

```python
# backend/scripts/init_clustering_tables.py
from sqlalchemy import create_engine, text
from app.database import Base, engine
from app.models import AnalysisTask, ClusterResult, AIReport

def init_tables():
    """åˆå§‹åŒ–èšç±»åˆ†æç›¸å…³è¡¨"""
    print("Creating clustering analysis tables...")
  
    # åˆ›å»ºæ‰€æœ‰è¡¨
    Base.metadata.create_all(bind=engine)
  
    # æ‰©å±•doctorsè¡¨
    with engine.connect() as conn:
        # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
        result = conn.execute(text("PRAGMA table_info(doctors)"))
        columns = [row[1] for row in result.fetchall()]
    
        if 'cluster_id' not in columns:
            conn.execute(text("ALTER TABLE doctors ADD COLUMN cluster_id INTEGER"))
            print("âœ“ Added cluster_id to doctors table")
    
        if 'cluster_label' not in columns:
            conn.execute(text("ALTER TABLE doctors ADD COLUMN cluster_label VARCHAR(50)"))
            print("âœ“ Added cluster_label to doctors table")
    
        # åˆ›å»ºç´¢å¼•
        conn.execute(text("CREATE INDEX IF NOT EXISTS idx_doctors_cluster ON doctors(cluster_id)"))
        print("âœ“ Created index on cluster_id")
    
        conn.commit()
  
    print("âœ… All clustering tables initialized successfully!")

if __name__ == "__main__":
    init_tables()
```

---

## 4. åç«¯å¼€å‘è¯¦è§£

### 4.1 æ ¸å¿ƒæœåŠ¡ï¼šanalysis_service.py

```python
# backend/app/services/analysis_service.py
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score, davies_bouldin_score
from sqlalchemy.orm import Session
from datetime import datetime
import json
import logging

from app.models import Doctor, ClusterResult, AnalysisTask
from app.core.exceptions import AnalysisException

logger = logging.getLogger(__name__)

class AnalysisService:
    """èšç±»åˆ†ææœåŠ¡ç±»"""
  
    def __init__(self, db: Session):
        self.db = db
        self.scaler = StandardScaler()
  
    def perform_clustering(
        self,
        k: int,
        features: list[str] = None,
        task_name: str = "K-Meansèšç±»åˆ†æ",
        user_id: int = None
    ) -> ClusterResult:
        """
        æ‰§è¡ŒK-Meansèšç±»åˆ†æ
    
        Args:
            k: èšç±»æ•°é‡ (2-10)
            features: ç‰¹å¾åˆ—è¡¨ï¼Œé»˜è®¤ ['rfm_frequency', 'rfm_monetary']
            task_name: ä»»åŠ¡åç§°
            user_id: åˆ›å»ºä»»åŠ¡çš„ç”¨æˆ·ID
    
        Returns:
            ClusterResultå¯¹è±¡
    
        Raises:
            AnalysisException: åˆ†æè¿‡ç¨‹ä¸­çš„é”™è¯¯
        """
        start_time = datetime.utcnow()
    
        try:
            # 1. åˆ›å»ºä»»åŠ¡è®°å½•
            task = self._create_task(k, features, task_name, user_id)
        
            # 2. éªŒè¯å‚æ•°
            self._validate_parameters(k, features)
        
            # 3. åŠ è½½æ•°æ®
            logger.info(f"Loading data for task {task.task_id}...")
            df = self._load_data()
        
            if len(df) < k:
                raise AnalysisException(f"æ•°æ®é‡ä¸è¶³ï¼šéœ€è¦è‡³å°‘{k}æ¡è®°å½•ï¼Œå½“å‰ä»…{len(df)}æ¡")
        
            # 4. æ•°æ®é¢„å¤„ç†
            logger.info("Preprocessing data...")
            X, feature_names = self._preprocess_data(df, features)
        
            # 5. æ‰§è¡Œèšç±»
            logger.info(f"Performing K-Means clustering with k={k}...")
            task.status = 'running'
            task.progress = 30
            self.db.commit()
        
            kmeans, labels = self._fit_kmeans(X, k)
            df['cluster'] = labels
        
            # 6. è®¡ç®—è¯„ä¼°æŒ‡æ ‡
            logger.info("Calculating evaluation metrics...")
            task.progress = 60
            self.db.commit()
        
            metrics = self._calculate_metrics(X, labels)
        
            # 7. è®¡ç®—èšç±»ç»Ÿè®¡
            logger.info("Computing cluster statistics...")
            task.progress = 80
            self.db.commit()
        
            cluster_stats = self._compute_cluster_stats(df, k, feature_names)
        
            # 8. ç”Ÿæˆä¸šåŠ¡æ ‡ç­¾
            cluster_labels = self._generate_business_labels(cluster_stats)
        
            # 9. å‡†å¤‡å¯è§†åŒ–æ•°æ®
            logger.info("Preparing visualization data...")
            viz_data = self._prepare_visualization_data(df, kmeans, k)
        
            # 10. æ›´æ–°doctorsè¡¨
            logger.info("Updating doctors table...")
            self._update_doctors_table(df, cluster_labels)
        
            # 11. ä¿å­˜èšç±»ç»“æœ
            result = ClusterResult(
                task_id=task.task_id,
                k_value=k,
                algorithm='k-means',
                features_used=json.dumps(feature_names),
                cluster_stats=json.dumps(cluster_stats),
                cluster_labels=json.dumps(cluster_labels),
                silhouette_score=float(metrics['silhouette']),
                inertia=float(metrics['inertia']),
                davies_bouldin_score=float(metrics.get('davies_bouldin', 0)),
                visualization_data=json.dumps(viz_data),
                is_active=True,
                created_at=datetime.utcnow()
            )
        
            self.db.add(result)
            self.db.commit()
            self.db.refresh(result)
        
            # 12. æ›´æ–°ä»»åŠ¡çŠ¶æ€
            execution_time = (datetime.utcnow() - start_time).total_seconds()
            task.status = 'completed'
            task.progress = 100
            task.result_id = result.cluster_id
            task.completed_at = datetime.utcnow()
            task.execution_time = execution_time
            self.db.commit()
        
            logger.info(f"âœ… Clustering completed in {execution_time:.2f}s")
            return result
        
        except Exception as e:
            logger.error(f"âŒ Clustering failed: {str(e)}")
            task.status = 'failed'
            task.error_message = str(e)
            self.db.commit()
            raise AnalysisException(f"èšç±»åˆ†æå¤±è´¥: {str(e)}")
  
    def _create_task(self, k: int, features: list[str], task_name: str, user_id: int) -> AnalysisTask:
        """åˆ›å»ºåˆ†æä»»åŠ¡è®°å½•"""
        task = AnalysisTask(
            task_name=task_name,
            task_type='clustering',
            parameters=json.dumps({
                'k': k,
                'features': features or ['rfm_frequency', 'rfm_monetary']
            }),
            status='pending',
            created_by=user_id,
            created_at=datetime.utcnow()
        )
        self.db.add(task)
        self.db.commit()
        self.db.refresh(task)
        return task
  
    def _validate_parameters(self, k: int, features: list[str]):
        """éªŒè¯å‚æ•°æœ‰æ•ˆæ€§"""
        if not 2 <= k <= 10:
            raise AnalysisException("Kå€¼å¿…é¡»åœ¨2-10ä¹‹é—´")
    
        if features:
            valid_features = ['rfm_frequency', 'rfm_monetary', 'rfm_recency']
            for f in features:
                if f not in valid_features:
                    raise AnalysisException(f"æ— æ•ˆçš„ç‰¹å¾: {f}")
  
    def _load_data(self) -> pd.DataFrame:
        """ä»æ•°æ®åº“åŠ è½½åŒ»ç”Ÿæ•°æ®"""
        doctors = self.db.query(Doctor).all()
    
        if not doctors:
            raise AnalysisException("æ•°æ®åº“ä¸­æ²¡æœ‰åŒ»ç”Ÿæ•°æ®")
    
        data = []
        for d in doctors:
            data.append({
                'npi': d.npi,
                'rfm_frequency': d.rfm_frequency or 0,
                'rfm_monetary': d.rfm_monetary or 0.0,
                'rfm_recency': (datetime.utcnow() - d.rfm_recency).days if d.rfm_recency else 365
            })
    
        df = pd.DataFrame(data)
        logger.info(f"Loaded {len(df)} doctors")
        return df
  
    def _preprocess_data(self, df: pd.DataFrame, features: list[str] = None) -> tuple:
        """æ•°æ®é¢„å¤„ç†"""
        if not features:
            features = ['rfm_frequency', 'rfm_monetary']
    
        # æå–ç‰¹å¾
        X = df[features].values
    
        # å¤„ç†å¼‚å¸¸å€¼ï¼ˆä½¿ç”¨99.9åˆ†ä½æ•°è£å‰ªï¼‰
        for i, feature in enumerate(features):
            percentile_999 = np.percentile(X[:, i], 99.9)
            X[:, i] = np.clip(X[:, i], 0, percentile_999)
            logger.info(f"{feature} clipped at {percentile_999:.2f}")
    
        # æ ‡å‡†åŒ–
        X_scaled = self.scaler.fit_transform(X)
    
        return X_scaled, features
  
    def _fit_kmeans(self, X: np.ndarray, k: int) -> tuple:
        """æ‰§è¡ŒK-Meansèšç±»"""
        kmeans = KMeans(
            n_clusters=k,
            random_state=42,
            n_init=10,
            max_iter=300,
            algorithm='lloyd'
        )
        labels = kmeans.fit_predict(X)
    
        logger.info(f"K-Means completed. Cluster sizes: {np.bincount(labels)}")
        return kmeans, labels
  
    def _calculate_metrics(self, X: np.ndarray, labels: np.ndarray) -> dict:
        """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
        silhouette = silhouette_score(X, labels)
        inertia = KMeans(n_clusters=len(np.unique(labels)), random_state=42).fit(X).inertia_
        davies_bouldin = davies_bouldin_score(X, labels)
    
        return {
            'silhouette': silhouette,
            'inertia': inertia,
            'davies_bouldin': davies_bouldin
        }
  
    def _compute_cluster_stats(
        self,
        df: pd.DataFrame,
        k: int,
        features: list[str]
    ) -> dict:
        """è®¡ç®—æ¯ä¸ªèšç±»çš„ç»Ÿè®¡ä¿¡æ¯"""
        stats = {}
    
        for cluster_id in range(k):
            cluster_df = df[df['cluster'] == cluster_id]
        
            stats[str(cluster_id)] = {
                'size': len(cluster_df),
                'size_percentage': round(len(cluster_df) / len(df) * 100, 2),
                'avg_frequency': round(cluster_df['rfm_frequency'].mean(), 2),
                'avg_monetary': round(cluster_df['rfm_monetary'].mean(), 2),
                'median_frequency': int(cluster_df['rfm_frequency'].median()),
                'median_monetary': round(cluster_df['rfm_monetary'].median(), 2),
                'std_monetary': round(cluster_df['rfm_monetary'].std(), 2),
                'min_monetary': round(cluster_df['rfm_monetary'].min(), 2),
                'max_monetary': round(cluster_df['rfm_monetary'].max(), 2)
            }
    
        return stats
  
    def _generate_business_labels(self, cluster_stats: dict) -> dict:
        """æ ¹æ®ç»Ÿè®¡ç‰¹å¾è‡ªåŠ¨ç”Ÿæˆä¸šåŠ¡æ ‡ç­¾"""
        labels = {}
    
        # æŒ‰å¹³å‡é‡‘é¢æ’åº
        sorted_clusters = sorted(
            cluster_stats.items(),
            key=lambda x: x[1]['avg_monetary'],
            reverse=True
        )
    
        for idx, (cluster_id, stats) in enumerate(sorted_clusters):
            avg_m = stats['avg_monetary']
            avg_f = stats['avg_frequency']
        
            if idx == 0:
                # æœ€é«˜é‡‘é¢
                if avg_f > 20:
                    labels[cluster_id] = "é¡¶çº§å®¢æˆ·"
                else:
                    labels[cluster_id] = "é«˜ä»·å€¼å®¢æˆ·"
            elif idx == len(sorted_clusters) - 1:
                # æœ€ä½é‡‘é¢
                labels[cluster_id] = "å¤§ä¼—å®¢æˆ·"
            else:
                # ä¸­é—´å±‚
                if avg_m > 3000:
                    labels[cluster_id] = "æ ¸å¿ƒå®¢æˆ·"
                else:
                    labels[cluster_id] = "æ½œåŠ›å®¢æˆ·"
    
        return labels
  
    def _prepare_visualization_data(
        self,
        df: pd.DataFrame,
        kmeans: KMeans,
        k: int
    ) -> dict:
        """å‡†å¤‡å¯è§†åŒ–æ•°æ®ï¼ˆé‡‡æ ·ä»¥å‡å°æ•°æ®é‡ï¼‰"""
        # é‡‡æ ·1000ä¸ªç‚¹ç”¨äºå‰ç«¯å±•ç¤º
        sample_size = min(1000, len(df))
        sample_df = df.sample(n=sample_size, random_state=42)
    
        scatter_data = []
        for _, row in sample_df.iterrows():
            scatter_data.append({
                'frequency': float(row['rfm_frequency']),
                'monetary': float(row['rfm_monetary']),
                'cluster': int(row['cluster']),
                'npi': row['npi']
            })
    
        # èšç±»ä¸­å¿ƒï¼ˆåæ ‡å‡†åŒ–ï¼‰
        centers = self.scaler.inverse_transform(kmeans.cluster_centers_)
    
        viz_data = {
            'scatter_data': scatter_data,
            'cluster_centers': centers.tolist(),
            'total_points': len(df),
            'sample_size': sample_size
        }
    
        return viz_data
  
    def _update_doctors_table(self, df: pd.DataFrame, cluster_labels: dict):
        """æ›´æ–°doctorsè¡¨çš„cluster_idå’Œcluster_label"""
        logger.info("Updating doctors table...")
    
        for _, row in df.iterrows():
            cluster_id = int(row['cluster'])
            label = cluster_labels.get(str(cluster_id), f"ç¾¤ç»„{cluster_id}")
        
            self.db.query(Doctor).filter(Doctor.npi == row['npi']).update({
                'cluster_id': cluster_id,
                'cluster_label': label,
                'updated_at': datetime.utcnow()
            })
    
        self.db.commit()
        logger.info(f"âœ“ Updated {len(df)} doctors")
  
    def get_clustering_results(self, cluster_id: int = None) -> list[ClusterResult]:
        """è·å–èšç±»ç»“æœ"""
        query = self.db.query(ClusterResult).filter(ClusterResult.is_active == True)
    
        if cluster_id:
            return query.filter(ClusterResult.cluster_id == cluster_id).first()
        else:
            return query.order_by(ClusterResult.created_at.desc()).limit(10).all()
  
    def calculate_optimal_k(
        self,
        max_k: int = 10,
        features: list[str] = None
    ) -> dict:
        """ä½¿ç”¨Elbowæ–¹æ³•è®¡ç®—æœ€ä¼˜Kå€¼"""
        df = self._load_data()
        X, _ = self._preprocess_data(df, features)
    
        results = {}
        for k in range(2, max_k + 1):
            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
            labels = kmeans.fit_predict(X)
        
            results[k] = {
                'inertia': float(kmeans.inertia_),
                'silhouette_score': float(silhouette_score(X, labels))
            }
    
        # ç®€å•æ¨èé€»è¾‘ï¼šé€‰æ‹©è½®å»“ç³»æ•°æœ€é«˜çš„K
        recommended_k = max(results.items(), key=lambda x: x[1]['silhouette_score'])[0]
    
        return {
            'results': results,
            'recommended_k': recommended_k
        }
```

### 4.2 APIè·¯ç”±ï¼šrouters/analysis.py

```python
# backend/app/routers/analysis.py
from fastapi import APIRouter, Depends, BackgroundTasks, HTTPException, Query
from sqlalchemy.orm import Session
from typing import Optional
import json

from app.database import get_db
from app.models import ClusterResult, AnalysisTask
from app.schemas import (
    ClusteringRequest,
    ClusteringResponse,
    ClusterResultResponse,
    AnalysisTaskResponse
)
from app.services.analysis_service import AnalysisService
from app.core.security import get_current_active_user
from app.core.exceptions import AnalysisException

router = APIRouter(prefix="/analysis", tags=["æ•°æ®åˆ†æ"])

@router.post("/perform", response_model=AnalysisTaskResponse)
async def perform_clustering(
    request: ClusteringRequest,
    background_tasks: BackgroundTasks,
    current_user = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    è§¦å‘K-Meansèšç±»åˆ†æï¼ˆå¼‚æ­¥æ‰§è¡Œï¼‰
  
    **å‚æ•°**:
    - k: èšç±»æ•°é‡ (2-10)
    - features: ç‰¹å¾åˆ—è¡¨ï¼Œé»˜è®¤ ['rfm_frequency', 'rfm_monetary']
    - task_name: ä»»åŠ¡åç§°
  
    **è¿”å›**:
    - task_id: ä»»åŠ¡ID
    - status: ä»»åŠ¡çŠ¶æ€
    """
    try:
        service = AnalysisService(db)
    
        # åŒæ­¥æ‰§è¡Œï¼ˆå°æ•°æ®é‡ï¼‰
        # å¦‚æœæ•°æ®é‡å¾ˆå¤§ï¼Œæ”¹ä¸ºå¼‚æ­¥ï¼šbackground_tasks.add_task(...)
        result = service.perform_clustering(
            k=request.k,
            features=request.features,
            task_name=request.task_name,
            user_id=current_user.id
        )
    
        # è·å–ä»»åŠ¡ä¿¡æ¯
        task = db.query(AnalysisTask).filter(
            AnalysisTask.result_id == result.cluster_id
        ).first()
    
        return {
            "task_id": task.task_id,
            "task_name": task.task_name,
            "status": task.status,
            "progress": task.progress,
            "result_id": result.cluster_id,
            "created_at": task.created_at
        }
    
    except AnalysisException as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ†æå¤±è´¥: {str(e)}")

@router.get("/results", response_model=list[ClusterResultResponse])
async def get_all_cluster_results(
    limit: int = Query(10, ge=1, le=50),
    current_user = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """è·å–æ‰€æœ‰èšç±»ç»“æœåˆ—è¡¨ï¼ˆåˆ†é¡µï¼‰"""
    service = AnalysisService(db)
    results = service.get_clustering_results()
  
    response = []
    for r in results[:limit]:
        response.append({
            "cluster_id": r.cluster_id,
            "k_value": r.k_value,
            "silhouette_score": r.silhouette_score,
            "inertia": r.inertia,
            "cluster_stats": json.loads(r.cluster_stats),
            "cluster_labels": json.loads(r.cluster_labels),
            "created_at": r.created_at
        })
  
    return response

@router.get("/results/{cluster_id}", response_model=ClusterResultResponse)
async def get_cluster_result_detail(
    cluster_id: int,
    current_user = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """è·å–æŒ‡å®šèšç±»ç»“æœçš„è¯¦ç»†ä¿¡æ¯ï¼ˆåŒ…å«å¯è§†åŒ–æ•°æ®ï¼‰"""
    result = db.query(ClusterResult).filter(
        ClusterResult.cluster_id == cluster_id
    ).first()
  
    if not result:
        raise HTTPException(status_code=404, detail="èšç±»ç»“æœä¸å­˜åœ¨")
  
    return {
        "cluster_id": result.cluster_id,
        "k_value": result.k_value,
        "algorithm": result.algorithm,
        "features_used": json.loads(result.features_used),
        "cluster_stats": json.loads(result.cluster_stats),
        "cluster_labels": json.loads(result.cluster_labels),
        "silhouette_score": result.silhouette_score,
        "inertia": result.inertia,
        "davies_bouldin_score": result.davies_bouldin_score,
        "visualization_data": json.loads(result.visualization_data),
        "created_at": result.created_at
    }

@router.get("/tasks/{task_id}/status", response_model=AnalysisTaskResponse)
async def get_task_status(
    task_id: int,
    current_user = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """æŸ¥è¯¢åˆ†æä»»åŠ¡çŠ¶æ€ï¼ˆç”¨äºè½®è¯¢ï¼‰"""
    task = db.query(AnalysisTask).filter(AnalysisTask.task_id == task_id).first()
  
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
  
    return {
        "task_id": task.task_id,
        "task_name": task.task_name,
        "status": task.status,
        "progress": task.progress,
        "error_message": task.error_message,
        "execution_time": task.execution_time,
        "result_id": task.result_id,
        "created_at": task.created_at,
        "completed_at": task.completed_at
    }

@router.get("/optimal-k")
async def calculate_optimal_k(
    max_k: int = Query(10, ge=2, le=15),
    current_user = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """è®¡ç®—æœ€ä¼˜Kå€¼ï¼ˆElbowæ–¹æ³•ï¼‰"""
    try:
        service = AnalysisService(db)
        result = service.calculate_optimal_k(max_k=max_k)
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.delete("/results/{cluster_id}")
async def delete_cluster_result(
    cluster_id: int,
    current_user = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """åˆ é™¤èšç±»ç»“æœï¼ˆè½¯åˆ é™¤ï¼‰"""
    result = db.query(ClusterResult).filter(
        ClusterResult.cluster_id == cluster_id
    ).first()
  
    if not result:
        raise HTTPException(status_code=404, detail="èšç±»ç»“æœä¸å­˜åœ¨")
  
    result.is_active = False
    db.commit()
  
    return {"message": "åˆ é™¤æˆåŠŸ"}
```

### 4.3 Pydantic Schemas

```python
# backend/app/schemas.pyï¼ˆæ·»åŠ éƒ¨åˆ†ï¼‰

from pydantic import BaseModel, Field
from typing import Optional, List
from datetime import datetime

class ClusteringRequest(BaseModel):
    """èšç±»åˆ†æè¯·æ±‚"""
    k: int = Field(..., ge=2, le=10, description="èšç±»æ•°é‡")
    features: Optional[List[str]] = Field(
        default=['rfm_frequency', 'rfm_monetary'],
        description="åˆ†æç‰¹å¾"
    )
    task_name: str = Field(..., description="ä»»åŠ¡åç§°")

class AnalysisTaskResponse(BaseModel):
    """åˆ†æä»»åŠ¡å“åº”"""
    task_id: int
    task_name: str
    status: str
    progress: int
    result_id: Optional[int]
    error_message: Optional[str]
    execution_time: Optional[float]
    created_at: datetime
    completed_at: Optional[datetime]
  
    class Config:
        from_attributes = True

class ClusterStats(BaseModel):
    """èšç±»ç»Ÿè®¡ä¿¡æ¯"""
    size: int
    size_percentage: float
    avg_frequency: float
    avg_monetary: float
    median_frequency: int
    median_monetary: float
    std_monetary: float
    label: str

class ClusterResultResponse(BaseModel):
    """èšç±»ç»“æœå“åº”"""
    cluster_id: int
    k_value: int
    algorithm: str
    features_used: List[str]
    cluster_stats: dict
    cluster_labels: dict
    silhouette_score: float
    inertia: float
    davies_bouldin_score: Optional[float]
    visualization_data: dict
    created_at: datetime
  
    class Config:
        from_attributes = True

class ClusteringResponse(BaseModel):
    """èšç±»åˆ†æå®Œæ•´å“åº”"""
    result: ClusterResultResponse
    task: AnalysisTaskResponse
```

---

## 5. å‰ç«¯å¼€å‘è¯¦è§£

### 5.1 é¡µé¢ç»“æ„ï¼ˆåŸºäºç°æœ‰UIï¼‰

ä»ä½ çš„æˆªå›¾çœ‹ï¼Œå‰ç«¯UIæ¡†æ¶å·²ç»å®Œæˆï¼Œéœ€è¦ï¼š

1. å®Œå–„å·¦ä¾§é…ç½®é¢æ¿çš„äº¤äº’
2. å®ç°å³ä¾§ç»“æœå±•ç¤ºåŒº
3. æ·»åŠ AIç­–ç•¥ç”Ÿæˆå¯¹è¯æ¡†

```vue
<!-- views/analysis/ClusterAnalysisView.vue -->
<template>
  <div class="analysis-container">
    <el-row :gutter="20">
      <!-- å·¦ä¾§ï¼šé…ç½®é¢æ¿ -->
      <el-col :xs="24" :md="8" :lg="6">
        <el-card class="config-card">
          <template #header>
            <div class="card-header">
              <el-icon><Setting /></el-icon>
              <span>èšç±»é…ç½®</span>
            </div>
          </template>
      
          <!-- Kå€¼æ»‘å— -->
          <div class="config-section">
            <div class="section-label">
              èšç±»æ•°é‡ (K)
              <el-tooltip content="å°†åŒ»ç”Ÿåˆ†ä¸ºKä¸ªç¾¤ç»„">
                <el-icon><QuestionFilled /></el-icon>
              </el-tooltip>
            </div>
            <el-slider
              v-model="config.k"
              :min="2"
              :max="10"
              :marks="marks"
              show-stops
              @change="handleKChange"
            />
            <div class="k-value-display">
              å½“å‰Kå€¼: <span class="highlight">{{ config.k }}</span>
            </div>
          </div>
      
          <!-- ç‰¹å¾é€‰æ‹© -->
          <div class="config-section">
            <div class="section-label">ç‰¹å¾é€‰æ‹©</div>
            <el-checkbox-group v-model="config.features">
              <el-checkbox label="rfm_frequency" disabled>
                <span>F - äº’åŠ¨é¢‘æ¬¡</span>
              </el-checkbox>
              <el-checkbox label="rfm_monetary" disabled>
                <span>M - æ€»é‡‘é¢</span>
              </el-checkbox>
              <el-checkbox label="rfm_recency" :disabled="true">
                <span>R - æœ€è¿‘äº’åŠ¨</span>
                <el-tag size="small" type="info">æœªæ¥æ”¯æŒ</el-tag>
              </el-checkbox>
            </el-checkbox-group>
          </div>
      
          <!-- ä»»åŠ¡åç§° -->
          <div class="config-section">
            <div class="section-label">ä»»åŠ¡åç§°</div>
            <el-input
              v-model="config.taskName"
              placeholder="ä¾‹å¦‚ï¼š2024å¹´åº¦åŒ»ç”Ÿåˆ†ç¾¤"
            />
          </div>
      
          <!-- æ“ä½œæŒ‰é’® -->
          <div class="action-buttons">
            <el-button
              type="primary"
              size="large"
              :loading="analyzing"
              :disabled="!canAnalyze"
              @click="handleStartAnalysis"
              class="start-btn"
            >
              <el-icon><DataAnalysis /></el-icon>
              {{ analyzing ? 'åˆ†æä¸­...' : 'å¼€å§‹åˆ†æ' }}
            </el-button>
        
            <el-button
              size="large"
              @click="showOptimalK = true"
              :disabled="analyzing"
            >
              <el-icon><TrendCharts /></el-icon>
              è®¡ç®—æœ€ä¼˜K
            </el-button>
        
            <el-button
              size="large"
              @click="viewHistory"
              :disabled="analyzing"
            >
              <el-icon><Clock /></el-icon>
              å†å²è®°å½•
            </el-button>
          </div>
        </el-card>
      </el-col>
  
      <!-- å³ä¾§ï¼šç»“æœå±•ç¤º -->
      <el-col :xs="24" :md="16" :lg="18">
        <!-- åˆ†æä¸­çŠ¶æ€ -->
        <div v-if="analyzing" class="analyzing-state">
          <el-card>
            <div class="progress-container">
              <div class="progress-icon">
                <el-icon class="rotating"><Loading /></el-icon>
              </div>
              <h3>æ­£åœ¨æ‰§è¡Œèšç±»åˆ†æ...</h3>
              <el-progress
                :percentage="progress"
                :stroke-width="12"
                :color="progressColors"
              />
              <p class="progress-text">{{ progressText }}</p>
            </div>
          </el-card>
    
```

## Dify Chatflow é›†æˆæˆåŠŸ

### âœ… å·²å®Œæˆ

1. **backend/app/services/dify_service.py** - å®Œæ•´å®ç°

* æ­£ç¡®çš„ payload æ ¼å¼:

  ```
  cluster_data
  ```

  ```
  user_focus
  ```

* ä½¿ç”¨

  ```
  /chat-messages
  ```

  ç«¯ç‚¹

* ```
  query
  ```

  å­—æ®µå¿…é¡»éç©º
* SSE æµå¼è§£æ
* å®Œå–„çš„é”™è¯¯å¤„ç†

1. **backend/app/routers/reports.py** - API ç«¯ç‚¹

* ```
  POST /api/v1/reports/generate-stream
  ```

  * SSE æµå¼å“åº”
* è‡ªåŠ¨ä¿å­˜ç”Ÿæˆçš„æŠ¥å‘Š

1. **æµ‹è¯•éªŒè¯** âœ…
   * çŠ¶æ€ç : **200 OK**
   * æ¥æ”¶: **26 ä¸ªæ•°æ®å—**
   * æ€»é•¿åº¦: **1999 å­—ç¬¦**

### ğŸ“‹ å…³é”®é…ç½®

<pre><div><div class="min-h-7 relative box-border flex flex-row items-center justify-between rounded-t border border-b-0 border-gray-500/25 px-2 py-0.5"><div class="font-sans text-sm text-ide-text-color opacity-60">python</div><div><div class="flex flex-row items-center gap-0.5"><div class="rounded-sm p-1 cursor-pointer opacity-60 hover:bg-gray-500/25 hover:opacity-100"><span data-tooltip-id="At mention" class="text-ide-text-color"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3.5 w-3.5"><path stroke-linecap="round" stroke-linejoin="round" d="M16.5 12a4.5 4.5 0 1 1-9 0 4.5 4.5 0 0 1 9 0Zm0 0c0 1.657 1.007 3 2.25 3S21 13.657 21 12a9 9 0 1 0-2.636 6.364M16.5 12V8.25"></path></svg></span></div><div class="rounded-sm p-1 cursor-pointer opacity-60 hover:bg-gray-500/25 hover:opacity-100"><span data-tooltip-id="Copy" class="text-ide-text-color"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-copy h-3.5 w-3.5"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></span></div></div></div></div><div class="language-python relative overflow-hidden rounded-b border-x border-b border-gray-500/25 bg-ide-editor-background p-2" aria-label="highlighted-code-language-python"><div class="w-full h-full text-xs cursor-text"><div class="code-block"><div class="code-line" data-line-number="1" data-line-start="1" data-line-end="1"><div class="line-content"><span class="mtk3"># Dify API Payload</span></div></div><div class="code-line" data-line-number="2" data-line-start="2" data-line-end="2"><div class="line-content"><span class="mtk1">{</span></div></div><div class="code-line" data-line-number="3" data-line-start="3" data-line-end="3"><div class="line-content"><span class="mtk1"></span><span class="mtk4">"inputs"</span><span class="mtk1">: {</span></div></div><div class="code-line" data-line-number="4" data-line-start="4" data-line-end="4"><div class="line-content"><span class="mtk1"></span><span class="mtk4">"cluster_data"</span><span class="mtk1">: </span><span class="mtk4">"<JSONå­—ç¬¦ä¸²>"</span><span class="mtk1">,  </span><span class="mtk3"># èšç±»ç»Ÿè®¡æ•°æ®</span></div></div><div class="code-line" data-line-number="5" data-line-start="5" data-line-end="5"><div class="line-content"><span class="mtk1"></span><span class="mtk4">"user_focus"</span><span class="mtk1">: </span><span class="mtk4">"<ç”¨æˆ·æŒ‡ä»¤>"</span><span class="mtk1"></span><span class="mtk3"># ç”¨æˆ·å…³æ³¨ç‚¹</span></div></div><div class="code-line" data-line-number="6" data-line-start="6" data-line-end="6"><div class="line-content"><span class="mtk1">    },</span></div></div><div class="code-line" data-line-number="7" data-line-start="7" data-line-end="7"><div class="line-content"><span class="mtk1"></span><span class="mtk4">"query"</span><span class="mtk1">: </span><span class="mtk4">"è¯·æ ¹æ®èšç±»æ•°æ®ç”Ÿæˆè¥é”€ç­–ç•¥æŠ¥å‘Š"</span><span class="mtk1">,  </span><span class="mtk3"># å¿…å¡«ï¼</span></div></div><div class="code-line" data-line-number="8" data-line-start="8" data-line-end="8"><div class="line-content"><span class="mtk1"></span><span class="mtk4">"response_mode"</span><span class="mtk1">: </span><span class="mtk4">"streaming"</span><span class="mtk1">,</span></div></div><div class="code-line" data-line-number="9" data-line-start="9" data-line-end="9"><div class="line-content"><span class="mtk1"></span><span class="mtk4">"user"</span><span class="mtk1">: </span><span class="mtk4">"user_id"</span></div></div><div class="code-line" data-line-number="10" data-line-start="10" data-line-end="10"><div class="line-content"><span class="mtk1">}</span></div></div></div></div></div></div></pre>

### ğŸ§ª æµ‹è¯•å‘½ä»¤

<pre><div><div class="min-h-7 relative box-border flex flex-row items-center justify-between rounded-t border border-b-0 border-gray-500/25 px-2 py-0.5"><div class="font-sans text-sm text-ide-text-color opacity-60">bash</div><div><div class="flex flex-row items-center gap-0.5"><div class="rounded-sm p-1 cursor-pointer opacity-60 hover:bg-gray-500/25 hover:opacity-100"><span data-tooltip-id="At mention" class="text-ide-text-color"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3.5 w-3.5"><path stroke-linecap="round" stroke-linejoin="round" d="M16.5 12a4.5 4.5 0 1 1-9 0 4.5 4.5 0 0 1 9 0Zm0 0c0 1.657 1.007 3 2.25 3S21 13.657 21 12a9 9 0 1 0-2.636 6.364M16.5 12V8.25"></path></svg></span></div><div class="rounded-sm p-1 cursor-pointer opacity-60 hover:bg-gray-500/25 hover:opacity-100"><span data-tooltip-id="Copy" class="text-ide-text-color"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-copy h-3.5 w-3.5"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></span></div></div></div></div><div class="language-bash relative overflow-hidden rounded-b border-x border-b border-gray-500/25 bg-ide-editor-background p-2" aria-label="highlighted-code-language-bash"><div class="w-full h-full text-xs cursor-text"><div class="code-block"><div class="code-line" data-line-number="1" data-line-start="1" data-line-end="1"><div class="line-content"><span class="mtk3"># ç®€å•æµ‹è¯• (æ— éœ€æ•°æ®åº“)</span></div></div><div class="code-line" data-line-number="2" data-line-start="2" data-line-end="2"><div class="line-content"><span class="mtk12">python</span><span class="mtk1"></span><span class="mtk4">scripts/test_dify_simple.py</span></div></div><div class="code-line" data-line-number="3" data-line-start="3" data-line-end="3"><div class="line-content"><span class="mtk1"></span></div></div><div class="code-line" data-line-number="4" data-line-start="4" data-line-end="4"><div class="line-content"><span class="mtk3"># å®Œæ•´æµ‹è¯• (éœ€è¦å…ˆè¿è¡Œèšç±»åˆ†æ)</span></div></div><div class="code-line" data-line-number="5" data-line-start="5" data-line-end="5"><div class="line-content"><span class="mtk12">python</span><span class="mtk1"></span><span class="mtk4">scripts/test_dify_integration.py</span></div></div></div></div></div></div></pre>

### ğŸ¯ å‰ç«¯ä½¿ç”¨

å‰ç«¯å·²ç»å‡†å¤‡å°±ç»ªï¼ç”¨æˆ·å¯ä»¥ï¼š

1. è¿›å…¥åˆ†æé¡µé¢
2. è¿è¡Œèšç±»åˆ†æ
3. ç‚¹å‡»"ç”ŸæˆAIç­–ç•¥"
4. å®æ—¶æŸ¥çœ‹æµå¼è¾“å‡ºçš„ Markdown æŠ¥å‘Š
