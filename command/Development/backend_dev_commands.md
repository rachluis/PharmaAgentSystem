# ğŸ”§ åç«¯å¼€å‘å®Œå–„æŒ‡ä»¤ - Phase 1 è¯¦ç»†ä»»åŠ¡

> **ç›®æ ‡**ï¼šå®Œå–„FastAPIåç«¯ï¼Œå»ºç«‹å®Œæ•´çš„æ•°æ®åº“ç»“æ„ï¼Œå®ç°æ‰€æœ‰æ ¸å¿ƒAPI
> **å½“å‰çŠ¶æ€**ï¼šé¡¹ç›®éª¨æ¶å­˜åœ¨ï¼Œpharma.dbæœ‰æ•°æ®ï¼Œä½†æ¨¡å‹å’ŒAPIä¸å®Œæ•´

---

## ğŸ—„ï¸ Task 1: æ‰©å±•æ•°æ®åº“æ¨¡å‹

### å‘½ä»¤ç»™AI Agentï¼š

```
è¯·å®Œå–„ backend/app/models.pyï¼Œå®ç°ä»¥ä¸‹7å¼ è¡¨çš„å®Œæ•´å®šä¹‰ï¼š

è¦æ±‚ï¼š
1. ä¿ç•™ç°æœ‰çš„ Doctor è¡¨ç»“æ„ï¼Œæ·»åŠ ä»¥ä¸‹æ–°å­—æ®µï¼š
   - full_name (VARCHAR(200))
   - city (VARCHAR(100))
   - cluster_label (VARCHAR(50))
   - total_payments (INTEGER, default=0)
   - avg_payment_amount (FLOAT, default=0.0)
   - last_payment_date (DATE)

2. åˆ›å»º User è¡¨ï¼ˆç”¨æˆ·è®¤è¯ï¼‰ï¼š
   - id: INTEGER, primary_key, autoincrement
   - username: VARCHAR(50), unique, not null
   - email: VARCHAR(100), unique, not null
   - password_hash: VARCHAR(255), not null
   - full_name: VARCHAR(100)
   - role: VARCHAR(20), default='viewer'  # admin/analyst/viewer
   - avatar_url: VARCHAR(255)
   - is_active: BOOLEAN, default=True
   - created_at: DATETIME, server_default=now()
   - updated_at: DATETIME, onupdate=now()
   - last_login: DATETIME

3. åˆ›å»º PaymentRecord è¡¨ï¼ˆæ”¯ä»˜è®°å½•ï¼‰ï¼š
   - id: INTEGER, primary_key
   - npi: VARCHAR(20), ForeignKey('doctors.npi')
   - payment_date: DATE, not null
   - amount: FLOAT, not null
   - payment_type: VARCHAR(100)
   - nature_of_payment: VARCHAR(200)
   - payer_name: VARCHAR(200)
   - created_at: DATETIME

4. åˆ›å»º AnalysisTask è¡¨ï¼ˆåˆ†æä»»åŠ¡ï¼‰ï¼š
   - task_id: INTEGER, primary_key
   - task_name: VARCHAR(200), not null
   - task_type: VARCHAR(50)  # 'clustering', 'rfm_analysis'
   - parameters: TEXT  # JSONæ ¼å¼
   - status: VARCHAR(20), default='pending'  # pending/running/completed/failed
   - progress: INTEGER, default=0
   - created_by: INTEGER, ForeignKey('users.id')
   - started_at: DATETIME
   - completed_at: DATETIME
   - error_message: TEXT
   - result_id: INTEGER, ForeignKey('cluster_results.cluster_id')
   - created_at: DATETIME

5. æ‰©å±•ç°æœ‰çš„ ClusterResult è¡¨ï¼Œæ·»åŠ ï¼š
   - task_id: INTEGER, ForeignKey('analysis_tasks.task_id')
   - algorithm: VARCHAR(50), default='k-means'
   - features_used: TEXT  # JSON
   - cluster_labels: TEXT  # JSON: {"0": "æ ¸å¿ƒå®¢æˆ·", ...}
   - silhouette_score: FLOAT
   - inertia: FLOAT
   - visualization_data: TEXT  # JSON
   - is_active: BOOLEAN, default=True

6. åˆ›å»º AIReport è¡¨ï¼ˆAIæŠ¥å‘Šï¼‰ï¼š
   - report_id: INTEGER, primary_key
   - report_title: VARCHAR(300), not null
   - report_type: VARCHAR(50)  # 'cluster_analysis', 'doctor_profile'
   - report_content: TEXT, not null
   - report_summary: TEXT
   - related_cluster_id: INTEGER, ForeignKey('cluster_results.cluster_id')
   - related_npi: VARCHAR(20)
   - generated_by: INTEGER, ForeignKey('users.id')
   - dify_conversation_id: VARCHAR(100)
   - generation_time: FLOAT
   - status: VARCHAR(20), default='draft'
   - view_count: INTEGER, default=0
   - created_at: DATETIME
   - updated_at: DATETIME

7. åˆ›å»º SystemLog è¡¨ï¼ˆç³»ç»Ÿæ—¥å¿—ï¼‰ï¼š
   - log_id: INTEGER, primary_key
   - user_id: INTEGER, ForeignKey('users.id')
   - action: VARCHAR(100)
   - module: VARCHAR(50)
   - ip_address: VARCHAR(50)
   - request_data: TEXT
   - response_status: INTEGER
   - created_at: DATETIME

é‡è¦ï¼š
- æ‰€æœ‰å¤–é”®è¦æ­£ç¡®å®šä¹‰å…³ç³»
- ä¸ºå¸¸ç”¨æŸ¥è¯¢å­—æ®µæ·»åŠ ç´¢å¼•ï¼ˆusername, email, npi, cluster_idç­‰ï¼‰
- ä½¿ç”¨ server_default=func.now() è€Œä¸æ˜¯ default=datetime.now()
- ç¡®ä¿ä¸ç°æœ‰æ•°æ®å…¼å®¹ï¼ˆDoctorè¡¨å·²æœ‰æ•°æ®ï¼‰
```

**éªŒè¯æ–¹æ³•**ï¼š

```bash
# è¿è¡Œåæ£€æŸ¥æ¨¡å‹æ˜¯å¦æ­£ç¡®
python -c "from app.models import User, Doctor, AIReport; print('Models loaded successfully')"
```

---

## ğŸ” Task 2: å®ç°å®‰å…¨æ¨¡å— 

### å‘½ä»¤ç»™AI Agentï¼š

```
è¯·åˆ›å»º backend/app/core/security.pyï¼Œå®ç°å®Œæ•´çš„JWTè®¤è¯ç³»ç»Ÿï¼š

è¦æ±‚ï¼š

1. å¯¼å…¥å¿…è¦çš„åº“ï¼š
from datetime import datetime, timedelta
from typing import Optional
from jose import JWTError, jwt
from passlib.context import CryptContext
from fastapi import Depends, HTTPException, status
from fastapi.security import OAuth2PasswordBearer
from sqlalchemy.orm import Session

2. é…ç½®å¸¸é‡ï¼š
SECRET_KEY = "your-secret-key-change-in-production-09d25e094faa6ca2556c818166b7a9563b93f7099f6f0f4caa6cf63b88e8d3e7"
ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES = 1440  # 24å°æ—¶

3. å®ç°ä»¥ä¸‹å‡½æ•°ï¼š

# å¯†ç åŠ å¯†
pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

def verify_password(plain_password: str, hashed_password: str) -> bool:
    """éªŒè¯å¯†ç """
    return pwd_context.verify(plain_password, hashed_password)

def get_password_hash(password: str) -> str:
    """å¯†ç åŠ å¯†"""
    return pwd_context.hash(password)

# JWT Token
def create_access_token(data: dict, expires_delta: Optional[timedelta] = None) -> str:
    """ç”ŸæˆJWT Token"""
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
  
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
    return encoded_jwt

# OAuth2
oauth2_scheme = OAuth2PasswordBearer(tokenUrl="/api/v1/auth/login")

def get_current_user(token: str = Depends(oauth2_scheme), db: Session = Depends(get_db)):
    """ä»Tokenè·å–å½“å‰ç”¨æˆ·"""
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="Could not validate credentials",
        headers={"WWW-Authenticate": "Bearer"},
    )
  
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        username: str = payload.get("sub")
        if username is None:
            raise credentials_exception
    except JWTError:
        raise credentials_exception
  
    from app.models import User
    user = db.query(User).filter(User.username == username).first()
    if user is None:
        raise credentials_exception
  
    return user

def get_current_active_user(current_user: User = Depends(get_current_user)):
    """è·å–æ¿€æ´»çš„ç”¨æˆ·"""
    if not current_user.is_active:
        raise HTTPException(status_code=400, detail="Inactive user")
    return current_user

4. æ·»åŠ è§’è‰²æ£€æŸ¥å‡½æ•°ï¼š
def require_role(required_role: str):
    """è§’è‰²æƒé™è£…é¥°å™¨"""
    def role_checker(current_user: User = Depends(get_current_active_user)):
        if current_user.role != required_role and current_user.role != 'admin':
            raise HTTPException(
                status_code=403,
                detail="Not enough permissions"
            )
        return current_user
    return role_checker
```

**éªŒè¯æ–¹æ³•**ï¼š

```python
# æµ‹è¯•å¯†ç åŠ å¯†
from app.core.security import get_password_hash, verify_password
hashed = get_password_hash("test123")
print(verify_password("test123", hashed))  # åº”è¯¥è¾“å‡º True
```

---

## ğŸ“ Task 3: åˆ›å»ºPydantic Schemas (20åˆ†é’Ÿ)

### å‘½ä»¤ç»™AI Agentï¼š

```
è¯·å®Œå–„ backend/app/schemas.pyï¼Œåˆ›å»ºæ‰€æœ‰APIçš„è¯·æ±‚/å“åº”æ¨¡å‹ï¼š

è¦æ±‚ï¼š

1. ç”¨æˆ·ç›¸å…³Schemasï¼š
from pydantic import BaseModel, EmailStr
from typing import Optional
from datetime import datetime

class UserBase(BaseModel):
    username: str
    email: EmailStr
    full_name: Optional[str] = None

class UserCreate(UserBase):
    password: str

class UserUpdate(BaseModel):
    email: Optional[EmailStr] = None
    full_name: Optional[str] = None

class UserResponse(UserBase):
    id: int
    role: str
    is_active: bool
    created_at: datetime
  
    class Config:
        from_attributes = True

class Token(BaseModel):
    access_token: str
    token_type: str
    user: UserResponse

class PasswordChange(BaseModel):
    old_password: str
    new_password: str

2. åŒ»ç”Ÿç›¸å…³Schemasï¼š
class DoctorBase(BaseModel):
    npi: str
    first_name: Optional[str]
    last_name: Optional[str]
    full_name: Optional[str]
    specialty: Optional[str]
    state: Optional[str]
    city: Optional[str]

class DoctorResponse(DoctorBase):
    rfm_frequency: Optional[int]
    rfm_monetary: Optional[float]
    rfm_recency: Optional[datetime]
    cluster_id: Optional[int]
    cluster_label: Optional[str]
    total_payments: int
    avg_payment_amount: float
    last_payment_date: Optional[datetime]
  
    class Config:
        from_attributes = True

class DoctorListResponse(BaseModel):
    total: int
    page: int
    page_size: int
    items: list[DoctorResponse]

class DoctorStatistics(BaseModel):
    total_doctors: int
    total_monetary: float
    avg_monetary: float
    avg_frequency: float
    specialty_distribution: dict
    state_distribution: dict
    cluster_distribution: dict

3. åˆ†æç›¸å…³Schemasï¼š
class ClusteringRequest(BaseModel):
    k: int
    features: Optional[list[str]] = ["rfm_frequency", "rfm_monetary"]
    task_name: str

class ClusterResultResponse(BaseModel):
    cluster_id: int
    k_value: int
    cluster_stats: dict
    silhouette_score: Optional[float]
    cluster_labels: Optional[dict]
    created_at: datetime
  
    class Config:
        from_attributes = True

class AnalysisTaskResponse(BaseModel):
    task_id: int
    task_name: str
    status: str
    progress: int
    created_at: datetime
  
    class Config:
        from_attributes = True

4. æŠ¥å‘Šç›¸å…³Schemasï¼š
class ReportGenerateRequest(BaseModel):
    report_type: str  # 'cluster_analysis', 'doctor_profile'
    cluster_id: Optional[int]
    custom_prompt: Optional[str]
    title: Optional[str]

class ReportResponse(BaseModel):
    report_id: int
    report_title: str
    report_type: str
    report_summary: Optional[str]
    status: str
    view_count: int
    created_at: datetime
  
    class Config:
        from_attributes = True

class ReportDetailResponse(ReportResponse):
    report_content: str
    related_cluster_id: Optional[int]
    generation_time: Optional[float]

5. é€šç”¨å“åº”Schemaï¼š
class APIResponse(BaseModel):
    code: int = 200
    message: str = "success"
    data: Optional[dict] = None
    timestamp: datetime = datetime.utcnow()
```

---

## ğŸ›£ï¸ Task 4: å®ç°è®¤è¯API (30åˆ†é’Ÿ)

### å‘½ä»¤ç»™AI Agentï¼š

```
è¯·åˆ›å»º backend/app/routers/auth.pyï¼Œå®ç°å®Œæ•´çš„è®¤è¯åŠŸèƒ½ï¼š

è¦æ±‚ï¼š

from fastapi import APIRouter, Depends, HTTPException, status
from fastapi.security import OAuth2PasswordRequestForm
from sqlalchemy.orm import Session
from datetime import datetime

from app.database import get_db
from app.models import User, SystemLog
from app.schemas import UserCreate, UserResponse, Token, PasswordChange
from app.core.security import (
    get_password_hash, 
    verify_password, 
    create_access_token,
    get_current_active_user
)

router = APIRouter(prefix="/auth", tags=["è®¤è¯"])

@router.post("/register", response_model=UserResponse)
async def register(user_data: UserCreate, db: Session = Depends(get_db)):
    """ç”¨æˆ·æ³¨å†Œ"""
    # 1. æ£€æŸ¥ç”¨æˆ·åæ˜¯å¦å­˜åœ¨
    if db.query(User).filter(User.username == user_data.username).first():
        raise HTTPException(400, "Username already exists")
  
    # 2. æ£€æŸ¥é‚®ç®±æ˜¯å¦å­˜åœ¨
    if db.query(User).filter(User.email == user_data.email).first():
        raise HTTPException(400, "Email already exists")
  
    # 3. åˆ›å»ºç”¨æˆ·
    db_user = User(
        username=user_data.username,
        email=user_data.email,
        full_name=user_data.full_name,
        password_hash=get_password_hash(user_data.password),
        role='viewer'  # æ–°ç”¨æˆ·é»˜è®¤ä¸ºviewer
    )
  
    db.add(db_user)
    db.commit()
    db.refresh(db_user)
  
    # 4. è®°å½•æ—¥å¿—
    log = SystemLog(
        user_id=db_user.id,
        action="register",
        module="auth"
    )
    db.add(log)
    db.commit()
  
    return db_user

@router.post("/login", response_model=Token)
async def login(
    form_data: OAuth2PasswordRequestForm = Depends(),
    db: Session = Depends(get_db)
):
    """ç”¨æˆ·ç™»å½•"""
    # 1. éªŒè¯ç”¨æˆ·
    user = db.query(User).filter(User.username == form_data.username).first()
    if not user or not verify_password(form_data.password, user.password_hash):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Incorrect username or password"
        )
  
    if not user.is_active:
        raise HTTPException(400, "User is inactive")
  
    # 2. ç”ŸæˆToken
    access_token = create_access_token(data={"sub": user.username})
  
    # 3. æ›´æ–°æœ€åç™»å½•æ—¶é—´
    user.last_login = datetime.utcnow()
    db.commit()
  
    # 4. è®°å½•æ—¥å¿—
    log = SystemLog(
        user_id=user.id,
        action="login",
        module="auth"
    )
    db.add(log)
    db.commit()
  
    return {
        "access_token": access_token,
        "token_type": "bearer",
        "user": user
    }

@router.get("/me", response_model=UserResponse)
async def get_current_user_info(
    current_user: User = Depends(get_current_active_user)
):
    """è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯"""
    return current_user

@router.put("/profile", response_model=UserResponse)
async def update_profile(
    email: Optional[str] = None,
    full_name: Optional[str] = None,
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """æ›´æ–°ä¸ªäººä¿¡æ¯"""
    if email:
        current_user.email = email
    if full_name:
        current_user.full_name = full_name
  
    db.commit()
    db.refresh(current_user)
    return current_user

@router.post("/change-password")
async def change_password(
    password_data: PasswordChange,
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """ä¿®æ”¹å¯†ç """
    # 1. éªŒè¯æ—§å¯†ç 
    if not verify_password(password_data.old_password, current_user.password_hash):
        raise HTTPException(400, "Old password is incorrect")
  
    # 2. æ›´æ–°å¯†ç 
    current_user.password_hash = get_password_hash(password_data.new_password)
    db.commit()
  
    return {"message": "Password changed successfully"}

@router.post("/logout")
async def logout(current_user: User = Depends(get_current_active_user)):
    """ç™»å‡ºï¼ˆå®¢æˆ·ç«¯åˆ é™¤Tokenï¼‰"""
    return {"message": "Logged out successfully"}

æ³¨æ„ï¼š
- æ‰€æœ‰é”™è¯¯è¦ç”¨HTTPExceptionæŠ›å‡º
- å¯†ç æ°¸è¿œä¸è¦åœ¨å“åº”ä¸­è¿”å›
- æ¯ä¸ªæ“ä½œéƒ½è¦è®°å½•åˆ°SystemLog
- Tokenè¿‡æœŸæ—¶é—´è®¾ç½®ä¸º24å°æ—¶
```

**æµ‹è¯•å‘½ä»¤**ï¼š

```bash
# å¯åŠ¨æœåŠ¡å™¨
uvicorn app.main:app --reload

# åœ¨å¦ä¸€ä¸ªç»ˆç«¯æµ‹è¯•
curl -X POST "http://localhost:8000/api/v1/auth/register" \
  -H "Content-Type: application/json" \
  -d '{"username":"test","email":"test@example.com","password":"test123"}'
```

---

## ğŸ¥ Task 5: å®ç°åŒ»ç”Ÿæ•°æ®API

### å‘½ä»¤ç»™AI Agentï¼š

```
è¯·å®Œå–„ backend/app/routers/doctors.pyï¼Œå®ç°æ‰€æœ‰åŒ»ç”Ÿæ•°æ®æ¥å£ï¼š

è¦æ±‚ï¼š

from fastapi import APIRouter, Depends, Query
from sqlalchemy.orm import Session
from sqlalchemy import func, distinct
from typing import Optional

from app.database import get_db
from app.models import Doctor, PaymentRecord
from app.schemas import DoctorListResponse, DoctorResponse, DoctorStatistics
from app.core.security import get_current_active_user

router = APIRouter(prefix="/doctors", tags=["åŒ»ç”Ÿæ•°æ®"])

@router.get("", response_model=DoctorListResponse)
async def get_doctors(
    page: int = Query(1, ge=1),
    page_size: int = Query(20, ge=1, le=100),
    specialty: Optional[str] = None,
    state: Optional[str] = None,
    cluster_id: Optional[int] = None,
    min_monetary: Optional[float] = None,
    max_monetary: Optional[float] = None,
    search: Optional[str] = None,  # æœç´¢NPIæˆ–å§“å
    sort_by: str = Query("rfm_monetary", regex="^(rfm_monetary|rfm_frequency|npi)$"),
    sort_order: str = Query("desc", regex="^(asc|desc)$"),
    current_user = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    åˆ†é¡µæŸ¥è¯¢åŒ»ç”Ÿåˆ—è¡¨ï¼Œæ”¯æŒå¤šæ¡ä»¶ç­›é€‰å’Œæ’åº
    """
    # 1. æ„å»ºåŸºç¡€æŸ¥è¯¢
    query = db.query(Doctor)
  
    # 2. åº”ç”¨ç­›é€‰æ¡ä»¶
    if specialty:
        query = query.filter(Doctor.specialty == specialty)
    if state:
        query = query.filter(Doctor.state == state)
    if cluster_id is not None:
        query = query.filter(Doctor.cluster_id == cluster_id)
    if min_monetary:
        query = query.filter(Doctor.rfm_monetary >= min_monetary)
    if max_monetary:
        query = query.filter(Doctor.rfm_monetary <= max_monetary)
    if search:
        query = query.filter(
            (Doctor.npi.contains(search)) |
            (Doctor.full_name.contains(search))
        )
  
    # 3. åº”ç”¨æ’åº
    sort_column = getattr(Doctor, sort_by)
    if sort_order == "desc":
        query = query.order_by(sort_column.desc())
    else:
        query = query.order_by(sort_column.asc())
  
    # 4. åˆ†é¡µ
    total = query.count()
    doctors = query.offset((page - 1) * page_size).limit(page_size).all()
  
    return {
        "total": total,
        "page": page,
        "page_size": page_size,
        "items": doctors
    }

@router.get("/{npi}", response_model=DoctorResponse)
async def get_doctor_detail(
    npi: str,
    current_user = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """è·å–åŒ»ç”Ÿè¯¦æƒ…"""
    doctor = db.query(Doctor).filter(Doctor.npi == npi).first()
    if not doctor:
        raise HTTPException(404, "Doctor not found")
  
    return doctor

@router.get("/statistics", response_model=DoctorStatistics)
async def get_statistics(
    current_user = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """è·å–åŒ»ç”Ÿæ•°æ®ç»Ÿè®¡"""
    # 1. åŸºç¡€ç»Ÿè®¡
    total_doctors = db.query(Doctor).count()
    total_monetary = db.query(func.sum(Doctor.rfm_monetary)).scalar() or 0.0
    avg_monetary = db.query(func.avg(Doctor.rfm_monetary)).scalar() or 0.0
    avg_frequency = db.query(func.avg(Doctor.rfm_frequency)).scalar() or 0.0
  
    # 2. ä¸“ä¸šåˆ†å¸ƒï¼ˆTop 10ï¼‰
    specialty_dist = db.query(
        Doctor.specialty,
        func.count(Doctor.npi).label('count')
    ).group_by(Doctor.specialty)\
     .order_by(func.count(Doctor.npi).desc())\
     .limit(10)\
     .all()
  
    # 3. åœ°åŒºåˆ†å¸ƒï¼ˆTop 10ï¼‰
    state_dist = db.query(
        Doctor.state,
        func.count(Doctor.npi).label('count')
    ).group_by(Doctor.state)\
     .order_by(func.count(Doctor.npi).desc())\
     .limit(10)\
     .all()
  
    # 4. èšç±»åˆ†å¸ƒ
    cluster_dist = db.query(
        Doctor.cluster_id,
        Doctor.cluster_label,
        func.count(Doctor.npi).label('count')
    ).filter(Doctor.cluster_id.isnot(None))\
     .group_by(Doctor.cluster_id, Doctor.cluster_label)\
     .all()
  
    return {
        "total_doctors": total_doctors,
        "total_monetary": float(total_monetary),
        "avg_monetary": float(avg_monetary),
        "avg_frequency": float(avg_frequency),
        "specialty_distribution": {s[0]: s[1] for s in specialty_dist},
        "state_distribution": {s[0]: s[1] for s in state_dist},
        "cluster_distribution": {
            f"cluster_{c[0]}": {
                "label": c[1],
                "count": c[2]
            } for c in cluster_dist
        }
    }

@router.get("/options/specialties")
async def get_specialties(
    current_user = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """è·å–æ‰€æœ‰ä¸“ä¸šåˆ—è¡¨ï¼ˆç”¨äºç­›é€‰å™¨ï¼‰"""
    specialties = db.query(distinct(Doctor.specialty))\
        .filter(Doctor.specialty.isnot(None))\
        .order_by(Doctor.specialty)\
        .all()
  
    return {"specialties": [s[0] for s in specialties]}

@router.get("/options/states")
async def get_states(
    current_user = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """è·å–æ‰€æœ‰å·åˆ—è¡¨ï¼ˆç”¨äºç­›é€‰å™¨ï¼‰"""
    states = db.query(distinct(Doctor.state))\
        .filter(Doctor.state.isnot(None))\
        .order_by(Doctor.state)\
        .all()
  
    return {"states": [s[0] for s in states]}

é‡è¦ï¼š
- æ‰€æœ‰æŸ¥è¯¢éƒ½è¦ä¼˜åŒ–ï¼Œé¿å…N+1é—®é¢˜
- åˆ†é¡µå‚æ•°è¦æœ‰åˆç†çš„é™åˆ¶
- ç»Ÿè®¡æŸ¥è¯¢è¦æ·»åŠ ç¼“å­˜ï¼ˆå¯é€‰ï¼‰
- è¿”å›çš„æ•°æ®è¦ç¬¦åˆå‰ç«¯éœ€è¦çš„æ ¼å¼
```

---

## ğŸ“Š Task 6: å®ç°åˆ†ææœåŠ¡

### å‘½ä»¤ç»™AI Agentï¼š

```
è¯·åˆ›å»º backend/app/services/analysis_service.pyï¼Œå®ç°K-Meansèšç±»æœåŠ¡ï¼š

è¦æ±‚ï¼š

import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score
from sqlalchemy.orm import Session
import json
from datetime import datetime

from app.models import Doctor, ClusterResult, AnalysisTask

class AnalysisService:
    def __init__(self, db: Session):
        self.db = db
  
    def perform_clustering(
        self,
        k: int,
        features: list[str] = None,
        task_name: str = "K-Meansèšç±»"
    ) -> ClusterResult:
        """
        æ‰§è¡ŒK-Meansèšç±»åˆ†æ
    
        Args:
            k: èšç±»æ•°é‡
            features: ä½¿ç”¨çš„ç‰¹å¾åˆ—è¡¨
            task_name: ä»»åŠ¡åç§°
    
        Returns:
            ClusterResultå¯¹è±¡
        """
        # 1. åŠ è½½æ•°æ®
        doctors = self.db.query(Doctor).all()
        if not doctors:
            raise ValueError("No doctor data available")
    
        df = pd.DataFrame([{
            'npi': d.npi,
            'rfm_frequency': d.rfm_frequency or 0,
            'rfm_monetary': d.rfm_monetary or 0.0
        } for d in doctors])
    
        # 2. å‡†å¤‡ç‰¹å¾
        if not features:
            features = ['rfm_frequency', 'rfm_monetary']
    
        X = df[features].values
    
        # 3. å¤„ç†å¼‚å¸¸å€¼å’Œæ ‡å‡†åŒ–
        # ç§»é™¤æç«¯å€¼ï¼ˆ>99.9åˆ†ä½æ•°ï¼‰
        for i, feature in enumerate(features):
            percentile_999 = np.percentile(X[:, i], 99.9)
            X[:, i] = np.clip(X[:, i], 0, percentile_999)
    
        # æ ‡å‡†åŒ–
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
    
        # 4. æ‰§è¡Œèšç±»
        kmeans = KMeans(
            n_clusters=k,
            random_state=42,
            n_init=10,
            max_iter=300
        )
        labels = kmeans.fit_predict(X_scaled)
        df['cluster'] = labels
    
        # 5. è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        silhouette = silhouette_score(X_scaled, labels)
        inertia = kmeans.inertia_
    
        # 6. è®¡ç®—æ¯ä¸ªèšç±»çš„ç»Ÿè®¡ä¿¡æ¯
        cluster_stats = {}
        cluster_labels_dict = {}
    
        for cluster_id in range(k):
            cluster_df = df[df['cluster'] == cluster_id]
        
            stats = {
                'size': len(cluster_df),
                'avg_frequency': float(cluster_df['rfm_frequency'].mean()),
                'median_frequency': float(cluster_df['rfm_frequency'].median()),
                'avg_monetary': float(cluster_df['rfm_monetary'].mean()),
                'median_monetary': float(cluster_df['rfm_monetary'].median()),
                'total_monetary': float(cluster_df['rfm_monetary'].sum())
            }
        
            # è‡ªåŠ¨ç”Ÿæˆæ ‡ç­¾
            label = self._generate_cluster_label(stats)
            cluster_labels_dict[str(cluster_id)] = label
        
            cluster_stats[str(cluster_id)] = {
                **stats,
                'label': label
            }
    
        # 7. å‡†å¤‡å¯è§†åŒ–æ•°æ®ï¼ˆé‡‡æ ·ä»¥å‡å°æ•°æ®é‡ï¼‰
        sample_size = min(1000, len(df))
        sample_df = df.sample(n=sample_size, random_state=42)
    
        visualization_data = {
            'scatter_data': sample_df[[
                'rfm_frequency', 
                'rfm_monetary', 
                'cluster'
            ]].to_dict('records'),
            'cluster_centers': kmeans.cluster_centers_.tolist(),
            'radar_data': [
                {
                    'cluster': str(i),
                    'label': cluster_labels_dict[str(i)],
                    'frequency': cluster_stats[str(i)]['avg_frequency'],
                    'monetary': cluster_stats[str(i)]['avg_monetary']
                }
                for i in range(k)
            ]
        }
    
        # 8. ä¿å­˜èšç±»ç»“æœ
        result = ClusterResult(
            k_value=k,
            algorithm='k-means',
            features_used=json.dumps(features),
            cluster_stats=json.dumps(cluster_stats),
            cluster_labels=json.dumps(cluster_labels_dict),
            silhouette_score=float(silhouette),
            inertia=float(inertia),
            visualization_data=json.dumps(visualization_data),
            is_active=True,
            created_at=datetime.utcnow()
        )
    
        # 9. æ›´æ–°doctorsè¡¨çš„cluster_idå’Œcluster_label
        for _, row in df.iterrows():
            self.db.query(Doctor).filter(Doctor.npi == row['npi']).update({
                'cluster_id': int(row['cluster']),
                'cluster_label': cluster_labels_dict[str(row['cluster'])]
            })
    
        # 10. ä¿å­˜åˆ°æ•°æ®åº“
        self.db.add(result)
        self.db.commit()
        self.db.refresh(result)
    
        return result
  
    def _generate_cluster_label(self, stats: dict) -> str:
        """
        æ ¹æ®ç»Ÿè®¡ç‰¹å¾è‡ªåŠ¨ç”Ÿæˆèšç±»æ ‡ç­¾
        """
        avg_monetary = stats['avg_monetary']
        avg_frequency = stats['avg_frequency']
    
        # åŸºäºé˜ˆå€¼çš„ç®€å•è§„åˆ™
        if avg_monetary > 10000 and avg_frequency > 20:
            return "é¡¶çº§å®¢æˆ·"
        elif avg_monetary > 5000:
            return "æ ¸å¿ƒå®¢æˆ·"
        elif avg_monetary > 1000:
            return "æ½œåŠ›å®¢æˆ·"
        else:
            return "å¤§ä¼—å®¢æˆ·"
  
    def calculate_optimal_k(
        self,
        max_k: int = 10,
        features: list[str] = None
    ) -> dict:
        """
        ä½¿ç”¨Elbowæ–¹æ³•ç¡®å®šæœ€ä¼˜Kå€¼
    
        Returns:
            åŒ…å«inertiaå’Œsilhouetteåˆ†æ•°çš„å­—å…¸
        """
        # åŠ è½½æ•°æ®
        doctors = self.db.query(Doctor).all()
        df = pd.DataFrame([{
            'rfm_frequency': d.rfm_frequency or 0,
            'rfm_monetary': d.rfm_monetary or 0.0
        } for d in doctors])
    
        if not features:
            features = ['rfm_frequency', 'rfm_monetary']
    
        X = df[features].values
    
        # æ ‡å‡†åŒ–
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
    
        # è®¡ç®—ä¸åŒKå€¼çš„æŒ‡æ ‡
        results = {}
        for k in range(2, max_k + 1):
            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
            labels = kmeans.fit_predict(X_scaled)
        
            results[k] = {
                'inertia': float(kmeans.inertia_),
                'silhouette_score': float(silhouette_score(X_scaled, labels))
            }
    
        return results

æ³¨æ„ï¼š
- ä½¿ç”¨æ ‡å‡†åŒ–é¿å…é‡çº§å·®å¼‚å½±å“èšç±»
- å¤„ç†å¼‚å¸¸å€¼ï¼ˆæç«¯å€¼è£å‰ªï¼‰
- å¯è§†åŒ–æ•°æ®è¦é‡‡æ ·ï¼Œé¿å…ä¼ è¾“è¿‡å¤§
- èšç±»æ ‡ç­¾è¦æœ‰ä¸šåŠ¡å«ä¹‰
```

---

## ğŸ”— Task 7: å®ç°åˆ†æAPI 

### å‘½ä»¤ç»™AI Agentï¼š

```
è¯·å®Œå–„ backend/app/routers/analysis.pyï¼Œå®ç°åˆ†æç›¸å…³çš„æ‰€æœ‰æ¥å£ï¼š

è¦æ±‚ï¼š

from fastapi import APIRouter, Depends, BackgroundTasks, HTTPException
from sqlalchemy.orm import Session
import json

from app.database import get_db
from app.models import ClusterResult, AnalysisTask
from app.schemas import (
    ClusteringRequest, 
    ClusterResultResponse,
    AnalysisTaskResponse
)
from app.services.analysis_service import AnalysisService
from app.core.security import get_current_active_user

router = APIRouter(prefix="/analysis", tags=["æ•°æ®åˆ†æ"])

def run_clustering_background(
    task_id: int,
    k: int,
    features: list[str],
    db: Session
):
    """åå°ä»»åŠ¡ï¼šæ‰§è¡Œèšç±»"""
    task = db.query(AnalysisTask).filter(AnalysisTask.task_id == task_id).first()
  
    try:
        # æ›´æ–°çŠ¶æ€
        task.status = "running"
        task.started_at = datetime.utcnow()
        db.commit()
    
        # æ‰§è¡Œèšç±»
        service = AnalysisService(db)
        result = service.perform_clustering(k, features, task.task_name)
    
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        task.status = "completed"
        task.progress = 100
        task.result_id = result.cluster_id
        task.completed_at = datetime.utcnow()
        db.commit()
    
    except Exception as e:
        task.status = "failed"
        task.error_message = str(e)
        db.commit()

@router.post("/perform", response_model=AnalysisTaskResponse)
async def perform_clustering(
    request: ClusteringRequest,
    background_tasks: BackgroundTasks,
    current_user = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    è§¦å‘K-Meansèšç±»åˆ†æï¼ˆå¼‚æ­¥æ‰§è¡Œï¼‰
    """
    # å‚æ•°éªŒè¯
    if request.k < 2 or request.k > 10:
        raise HTTPException(400, "K must be between 2 and 10")
  
    # åˆ›å»ºä»»åŠ¡è®°å½•
    task = AnalysisTask(
        task_name=request.task_name,
        task_type="clustering",
        parameters=json.dumps({
            "k": request.k,
            "features": request.features
        }),
        status="pending",
        created_by=current_user.id
    )
  
    db.add(task)
    db.commit()
    db.refresh(task)
  
    # æ·»åŠ åå°ä»»åŠ¡
    background_tasks.add_task(
        run_clustering_background,
        task.task_id,
        request.k,
        request.features,
        db
    )
  
    return task

@router.get("/results", response_model=list[ClusterResultResponse])
async def get_all_cluster_results(
    limit: int = 10,
    current_user = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """è·å–æ‰€æœ‰èšç±»ç»“æœåˆ—è¡¨"""
    results = db.query(ClusterResult)\
        .order_by(ClusterResult.created_at.desc())\
        .limit(limit)\
        .all()
  
    return results

@router.get("/results/{cluster_id}", response_model=ClusterResultResponse)
async def get_cluster_result(
    cluster_id: int,
    current_user = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """è·å–æŒ‡å®šèšç±»ç»“æœçš„è¯¦æƒ…"""
    result = db.query(ClusterResult)\
        .filter(ClusterResult.cluster_id == cluster_id)\
        .first()
  
    if not result:
        raise HTTPException(404, "Cluster result not found")
  
    # è§£æJSONå­—æ®µ
    response_data = {
        "cluster_id": result.cluster_id,
        "k_value": result.k_value,
        "cluster_stats": json.loads(result.cluster_stats),
        "cluster_labels": json.loads(result.cluster_labels) if result.cluster_labels else {},
        "silhouette_score": result.silhouette_score,
        "inertia": result.inertia,
        "visualization_data": json.loads(result.visualization_data) if result.visualization_data else {},
        "created_at": result.created_at
    }
  
    return response_data

@router.get("/tasks/{task_id}/status", response_model=AnalysisTaskResponse)
async def get_task_status(
    task_id: int,
    current_user = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """æŸ¥è¯¢åˆ†æä»»åŠ¡çŠ¶æ€"""
    task = db.query(AnalysisTask)\
        .filter(AnalysisTask.task_id == task_id)\
        .first()
  
    if not task:
        raise HTTPException(404, "Task not found")
  
    return task

@router.get("/optimal-k")
async def calculate_optimal_k(
    max_k: int = 10,
    current_user = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """è®¡ç®—æœ€ä¼˜Kå€¼ï¼ˆElbowæ–¹æ³•ï¼‰"""
    service = AnalysisService(db)
    results = service.calculate_optimal_k(max_k)
  
    return {
        "results": results,
        "recommendation": "Based on elbow method, K=3 is recommended"
    }

æ³¨æ„ï¼š
- èšç±»ä»»åŠ¡è¦å¼‚æ­¥æ‰§è¡Œï¼Œé¿å…é˜»å¡
- æä¾›ä»»åŠ¡çŠ¶æ€æŸ¥è¯¢æ¥å£
- JSONå­—æ®µè¦æ­£ç¡®è§£æåè¿”å›
- æ·»åŠ é€‚å½“çš„é”™è¯¯å¤„ç†
```

---

## ğŸ“ éªŒæ”¶æ ‡å‡†

å®Œæˆä»¥ä¸Šæ‰€æœ‰ä»»åŠ¡åï¼Œåº”è¯¥æ»¡è¶³ï¼š

âœ… **æ•°æ®åº“**ï¼š

- 7å¼ è¡¨å…¨éƒ¨åˆ›å»ºæˆåŠŸ
- ç´¢å¼•æ­£ç¡®å»ºç«‹
- å¤–é”®å…³ç³»æ­£ç¡®

âœ… **è®¤è¯ç³»ç»Ÿ**ï¼š

- å¯ä»¥æ³¨å†Œæ–°ç”¨æˆ·
- å¯ä»¥ç™»å½•å¹¶è·å¾—JWT Token
- TokenéªŒè¯æ­£å¸¸å·¥ä½œ
- å¯ä»¥è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯

âœ… **åŒ»ç”Ÿæ•°æ®API**ï¼š

- å¯ä»¥åˆ†é¡µæŸ¥è¯¢åŒ»ç”Ÿåˆ—è¡¨
- ç­›é€‰å’Œæ’åºåŠŸèƒ½æ­£å¸¸
- ç»Ÿè®¡æ¥å£è¿”å›æ­£ç¡®æ•°æ®
- ä¸“ä¸šå’Œå·åˆ—è¡¨æ¥å£æ­£å¸¸

âœ… **åˆ†æåŠŸèƒ½**ï¼š

- å¯ä»¥è§¦å‘K-Meansèšç±»
- èšç±»ç»“æœæ­£ç¡®ä¿å­˜
- å¯ä»¥æŸ¥è¯¢èšç±»ç»“æœ
- å¯è§†åŒ–æ•°æ®æ ¼å¼æ­£ç¡®

âœ… **æ–‡æ¡£**ï¼š

- Swaggeræ–‡æ¡£å®Œæ•´
- æ‰€æœ‰æ¥å£éƒ½æœ‰æè¿°
- å¯ä»¥åœ¨çº¿æµ‹è¯•

---

## ğŸ¯ ä¸‹ä¸€æ­¥

å®ŒæˆPhase 1åï¼Œä½ å¯ä»¥ï¼š

1. å‰ç«¯å¯¹æ¥è¿™äº›æ–°API
2. å¼€å§‹Phase 3çš„Difyé›†æˆ
3. å®ç°æŠ¥å‘Šç”ŸæˆåŠŸèƒ½

æœ‰ä»»ä½•é—®é¢˜éšæ—¶åé¦ˆï¼
